{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/python: No module named trainer\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "../run.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../run.sh\n",
    "export REGION=us-central1\n",
    "export BUCKET=keras-imdb-wiki\n",
    "export JOB_NAME=\"Keras_imbd_wiki$(date +%Y%m%d_%H%M%S)\"\n",
    "export JOB_DIR=gs://$BUCKET/$JOB_NAME\n",
    "\n",
    "#gcloud ml-engine jobs submit training $JOB_NAME  \\\n",
    "#--job-dir $JOB_DIR \\\n",
    "#--module-name trainer.model \\\n",
    "#--package-path ./trainer/ \\\n",
    "#--region $REGION \\\n",
    "#--\\\n",
    " #--train-file gs://$BUCKET/dataset/gender\n",
    "\n",
    "gcloud ml-engine local train \\\n",
    "--job-dir output \\\n",
    "--module-name trainer.model \\\n",
    "--package-path ./trainer/ \\\n",
    "--\\\n",
    " --train-file ../NP_CELEB/train \\\n",
    " --job-type 0 \\\n",
    " --predict-dir vgg_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load model.py\n",
    "import argparse\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from io import BytesIO\n",
    "\n",
    "import cPickle\n",
    "import pickle\n",
    "\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "from keras.applications import vgg16\n",
    "\n",
    "def get_data(train_dir, batch_size=32, input_shape=(32, 32, 3)):\n",
    "\n",
    "\twith file_io.FileIO(train_dir +\"/id.txt\", mode='r') as input_fn:\n",
    "\t\tids = pickle.load(input_fn)\n",
    "\t\n",
    "\tgenerator = DataGenerator(dim_x = input_shape[0], dim_y = input_shape[1], dim_z = input_shape[2], batch_size = batch_size, shuffle=False, train_dir=train_dir)\n",
    "\n",
    "\ttrain_generator = generator.generate(ids)\n",
    "\n",
    "\treturn train_generator\n",
    "\n",
    "\n",
    "def define_model(weights_path=None):\n",
    "\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Flatten(input_shape=(8,8,512)))\n",
    "\tmodel.add(Dense(4096, activation='relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(4096, activation='relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\tif weights_path:\n",
    "\t\tweights = np.load(weights_path)\n",
    "\t\tmodel.set_weights(weights)\n",
    "\n",
    "\tsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "\tmodel.compile(loss='categorical_crossentropy',\n",
    "\t          optimizer=sgd,\n",
    "\t          metrics=['accuracy'])\n",
    "\n",
    "\treturn model\n",
    "\n",
    "def bottleneck_features(train_dir, batch_size=32, number_of_samples=20000, input_shape=(1,32,32), output_dir=\"vgg_preditc\"):\n",
    "\n",
    "\tmodel = vgg16.VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "\n",
    "\t#generator = DataGenerator(dim_x = input_shape[0], dim_y = input_shape[1], dim_z = input_shape[2], batch_size = batch_size, shuffle = False, train_dir=train_dir)\n",
    "\n",
    "\tpredict_generator = get_data(train_dir, batch_size=batch_size, input_shape=input_shape)\n",
    "\n",
    "\tj = 1\n",
    "\tn = number_of_samples/batch_size\n",
    "\tfor i in range(n):\n",
    "\n",
    "\t\tprint(\"Predicting batch {}/{}\".format(i, n))\n",
    "\n",
    "\t\tX_batch, y_batch = predict_generator.next()\n",
    "\n",
    "\t\ty = model.predict(X_batch)\n",
    "\n",
    "\t\tfor sample in range(y.shape[0]):\n",
    "\t\t\twith file_io.FileIO(output_dir+'/'+str(y_batch[sample])+'/'+str(j)+'.npy', mode='w+') as output:\n",
    "\t\t\t\tnp.save(output, y)\n",
    "\t\t\t\tj = j + 1\n",
    "\n",
    "\n",
    "def train_model(model, train_generator, steps_per_epoch=3):\n",
    "\tmodel.fit_generator(train_generator, epochs=1, steps_per_epoch=steps_per_epoch)\n",
    "\n",
    "\treturn model\n",
    "\n",
    "def save_model(model, job_dir):\n",
    "\tmodel.save('model.h5')\n",
    "    \n",
    "\t# Save model.h5 on to google storage\n",
    "\twith file_io.FileIO('model.h5', mode='r') as input_f:\n",
    "\t\twith file_io.FileIO(job_dir + '/model.h5', mode='w') as output_f:\n",
    "\t\t\toutput_f.write(input_f.read())\n",
    "\n",
    "\n",
    "class DataGenerator(object):\n",
    "\t'Generates data for Keras'\n",
    "\tdef __init__(self, dim_x = 32, dim_y = 32, dim_z = 32, batch_size = 32, shuffle = False, train_dir=None):\n",
    "\t\t'Initialization'\n",
    "\t\tself.dim_x = dim_x\n",
    "\t\tself.dim_y = dim_y\n",
    "\t\tself.dim_z = dim_z\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tself.shuffle = shuffle\n",
    "\n",
    "\t\tif train_dir == None:\n",
    "\t\t\tprint \"Thunderfuck passou aqui! Deu erro abestado. Ai dento!! Iiiihhii!\"\n",
    "\t\t\traise ValueError\n",
    "\n",
    "\t\tself.train_dir = train_dir\n",
    "\n",
    "\tdef generate(self, list_IDs):\n",
    "\t\t'Generates batches of samples'\n",
    "\t\t# Infinite loop\n",
    "\t\twhile 1:\n",
    "\t\t\t# Generate order of exploration of dataset\n",
    "\t\t\tindexes = self.__get_exploration_order(list_IDs)\n",
    "\n",
    "\t\t\t# Generate batches\n",
    "\t\t\timax = int(len(indexes)/self.batch_size)\n",
    "\t\t\tfor i in range(imax):\n",
    "\t\t\t\tprint(\"i generate\", i)\n",
    "\t\t\t\t# Find list of IDs\n",
    "\t\t\t\tlist_IDs_temp = [list_IDs[k] for k in indexes[i*self.batch_size:(i+1)*self.batch_size]]\n",
    "\n",
    "\t\t\tprint(list_IDs_temp)\n",
    "\n",
    "\t\t\t# Generate data\n",
    "\t\t\tX, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "\t\t\tyield X, y\n",
    "\n",
    "\tdef __get_exploration_order(self, list_IDs):\n",
    "\t\t'Generates order of exploration'\n",
    "\t\t# Find exploration order\n",
    "\t\tindexes = np.arange(len(list_IDs))\n",
    "\t\tif self.shuffle == True:\n",
    "\t\t\tnp.random.shuffle(indexes)\n",
    "\n",
    "\t\treturn indexes\n",
    "\n",
    "\tdef __data_generation(self, list_IDs_temp):\n",
    "\t\t'Generates data of batch_size samples' # X : (n_samples, v_size, v_size, v_size, n_channels)\n",
    "\t\t# Initialization\n",
    "\t\tX = np.empty((self.batch_size, self.dim_x, self.dim_y, self.dim_z))\n",
    "\t\ty = np.empty((self.batch_size), dtype = int)\n",
    "\n",
    "\t\t# Generate data\n",
    "\t\tfor i, ID in enumerate(list_IDs_temp):\n",
    "\t\t\t#print(ID)\n",
    "\t\t\t#print(\"Entrou para pegar dados do bucket\")\n",
    "\t\t\t#print(ID.split('.')[0])\n",
    "\t\t\tf = BytesIO(file_io.read_file_to_string(self.train_dir +\"/\" + str(ID[0]) + \"/\" + ID))\n",
    "\t\t\t# Store volume\n",
    "\t\t\tX[i, :, :, :] = np.load(f)\n",
    "\n",
    "\t\t\t# Store class\n",
    "\t\t\ty[i] = int(ID[0])\n",
    "\t\tprint(\"Retornando um batch\")\n",
    "\t\treturn X, self.sparsify(y)\n",
    "\n",
    "\tdef sparsify(self, y):\n",
    "\t\t'Returns labels in binary NumPy array'\n",
    "\t\tn_classes = 2 # Enter number of classes\n",
    "\t\treturn np.array([[1 if y[i] == j else 0 for j in range(n_classes)]\n",
    "\t\t\tfor i in range(y.shape[0])])\n",
    "\t\tprint(\"terminou de sparsify\")\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "\tparser = argparse.ArgumentParser()\n",
    "\t# Input Arguments\n",
    "\tparser.add_argument(\n",
    "\t\t'--train-file',\n",
    "\t\thelp='GCS or local paths to training data',\n",
    "\t\trequired=True\n",
    "\t)\n",
    "\n",
    "\tparser.add_argument(\n",
    "\t\t'--job-dir',\n",
    "\t\thelp='GCS location to write checkpoints and export models',\n",
    "\t\trequired=True\n",
    "\t)\n",
    "\n",
    "\tparser.add_argument(\n",
    "\t\t'--job-type',\n",
    "\t\thelp='The type of job. It is 1 if it a normal job. It is 0 if the job is for getting the predict from vgg16.',\n",
    "\t\trequired=True\n",
    "\t)\n",
    "\n",
    "\tparser.add_argument(\n",
    "\t\t'--predict-dir',\n",
    "\t\thelp='Dir to save the predict form vgg',\n",
    "\t\trequired=False\n",
    "\t)\n",
    "\n",
    "\targs = parser.parse_args()\n",
    "\targuments = args.__dict__\n",
    "\tjob_dir = arguments.pop('job_dir')\n",
    "\ttrain_dir = arguments['train_file']\n",
    "\tjob_type = arguments['job_type']\n",
    "\n",
    "\t#train_generator = get_data(train_dir)\n",
    "\t\n",
    "\n",
    "\tif(job_type == \"1\"):\n",
    "\t\tmodel = define_model()\n",
    "\t\tmodel = train_model(model, train_generator)\n",
    "\t\tsave_model(model, job_dir)\n",
    "\n",
    "\telif(job_type == \"0\"):\n",
    "\t\tif(arguments['predict_dir']):\n",
    "\t\t\toutput_predict = arguments['predict_dir']\n",
    "\t\t\tbottleneck_features(train_dir, batch_size=32, number_of_samples=100, input_shape=(218, 178, 3), output_dir=output_predict)\n",
    "\t\telse:\n",
    "\t\t\tprint(\"The predict output dir has not been provided.\")\n",
    "\n",
    "\t\t\traise ValueError\n",
    "\n",
    "\n",
    "\telse:\n",
    "\t\tprint(\"Invalid job type.\")\n",
    "\t\traise ValueError\n",
    "\t\n",
    "\n",
    "\t#np.save(\"my_weights\", model.get_weights)[]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tmain()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
